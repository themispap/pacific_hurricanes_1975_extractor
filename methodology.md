In this project, I developed a web scraper to extract information about the 1975 Pacific hurricane season from a Wikipedia page. Using Python's requests library and BeautifulSoup, I retrieved and parsed the HTML content of the page. The scraper targeted specific HTML elements, including hurricane/storm names and their associated data such as start and end dates. Additionally, I extracted descriptive text about each storm to gather further details on the affected areas and the number of deaths.

For the data extraction process, I leveraged the OpenAI GPT model, which analyzed the textual information and returned structured outputs such as the number of deaths and a list of affected areas for each storm. The quality of the extracted data was assessed by comparing it with the original Wikipedia content, ensuring that the outputs matched expected patterns (e.g., storm names, dates, and accurate numeric values for deaths). Any discrepancies would be addressed by refining the scraping logic or adjusting the prompts fed to the GPT model for more accurate results. The final dataset was exported to a CSV file for further analysis.